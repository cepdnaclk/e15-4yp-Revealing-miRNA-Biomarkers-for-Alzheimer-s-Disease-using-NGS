{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsa-mir-30a:hsa-miR-30a-3p</th>\n",
       "      <th>hsa-mir-550a-1:hsa-miR-550a-3p</th>\n",
       "      <th>hsa-mir-29a:hsa-miR-29a-3p</th>\n",
       "      <th>hsa-mir-628:hsa-miR-628-3p</th>\n",
       "      <th>hsa-mir-26a-2:hsa-miR-26a-5p</th>\n",
       "      <th>hsa-mir-106b:hsa-miR-106b-5p</th>\n",
       "      <th>hsa-mir-4781:hsa-miR-4781-3p</th>\n",
       "      <th>hsa-mir-10b:hsa-miR-10b-5p</th>\n",
       "      <th>hsa-mir-215:hsa-miR-215</th>\n",
       "      <th>hsa-mir-548aj-2:hsa-miR-548g-5p</th>\n",
       "      <th>...</th>\n",
       "      <th>brain-mir-431:brain-mir-431</th>\n",
       "      <th>brain-mir-23:brain-mir-23</th>\n",
       "      <th>brain-mir-427:brain-mir-427</th>\n",
       "      <th>brain-mir-392:brain-mir-392</th>\n",
       "      <th>brain-mir-192:brain-mir-192</th>\n",
       "      <th>brain-mir-53:brain-mir-53</th>\n",
       "      <th>brain-mir-112:brain-mir-112</th>\n",
       "      <th>brain-mir-159:brain-mir-159</th>\n",
       "      <th>brain-mir-328:brain-mir-328</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AD.1</th>\n",
       "      <td>132.885714</td>\n",
       "      <td>958.457143</td>\n",
       "      <td>78.957143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3546.471429</td>\n",
       "      <td>117.857143</td>\n",
       "      <td>21.828571</td>\n",
       "      <td>902.114286</td>\n",
       "      <td>6335.742857</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>21.828571</td>\n",
       "      <td>12.471429</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>6.385714</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>13.571429</td>\n",
       "      <td>310.414286</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.2</th>\n",
       "      <td>282.371429</td>\n",
       "      <td>794.542857</td>\n",
       "      <td>64.457143</td>\n",
       "      <td>1.542857</td>\n",
       "      <td>14464.157143</td>\n",
       "      <td>40.428571</td>\n",
       "      <td>35.728571</td>\n",
       "      <td>1840.628571</td>\n",
       "      <td>3969.000000</td>\n",
       "      <td>5.157143</td>\n",
       "      <td>...</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>23.942857</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>16.985714</td>\n",
       "      <td>10.485714</td>\n",
       "      <td>7.414286</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>297.985714</td>\n",
       "      <td>16.371429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.3</th>\n",
       "      <td>179.371429</td>\n",
       "      <td>541.785714</td>\n",
       "      <td>69.814286</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>8648.271429</td>\n",
       "      <td>18.542857</td>\n",
       "      <td>23.057143</td>\n",
       "      <td>1459.242857</td>\n",
       "      <td>2045.757143</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>19.085714</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>14.871429</td>\n",
       "      <td>275.814286</td>\n",
       "      <td>16.185714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.4</th>\n",
       "      <td>115.700000</td>\n",
       "      <td>1011.342857</td>\n",
       "      <td>65.542857</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>7038.985714</td>\n",
       "      <td>72.342857</td>\n",
       "      <td>31.471429</td>\n",
       "      <td>289.042857</td>\n",
       "      <td>2860.557143</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>9.514286</td>\n",
       "      <td>28.257143</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>9.514286</td>\n",
       "      <td>7.185714</td>\n",
       "      <td>13.442857</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>275.814286</td>\n",
       "      <td>14.757143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.5</th>\n",
       "      <td>89.857143</td>\n",
       "      <td>429.757143</td>\n",
       "      <td>32.228571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4315.285714</td>\n",
       "      <td>84.800000</td>\n",
       "      <td>27.728571</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>1621.442857</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>...</td>\n",
       "      <td>15.428571</td>\n",
       "      <td>9.514286</td>\n",
       "      <td>37.728571</td>\n",
       "      <td>27.728571</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>15.428571</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>187.242857</td>\n",
       "      <td>6.457143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsa-mir-30a:hsa-miR-30a-3p</th>\n",
       "      <th>hsa-mir-550a-1:hsa-miR-550a-3p</th>\n",
       "      <th>hsa-mir-29a:hsa-miR-29a-3p</th>\n",
       "      <th>hsa-mir-628:hsa-miR-628-3p</th>\n",
       "      <th>hsa-mir-26a-2:hsa-miR-26a-5p</th>\n",
       "      <th>hsa-mir-106b:hsa-miR-106b-5p</th>\n",
       "      <th>hsa-mir-4781:hsa-miR-4781-3p</th>\n",
       "      <th>hsa-mir-10b:hsa-miR-10b-5p</th>\n",
       "      <th>hsa-mir-215:hsa-miR-215</th>\n",
       "      <th>hsa-mir-548aj-2:hsa-miR-548g-5p</th>\n",
       "      <th>...</th>\n",
       "      <th>brain-mir-431:brain-mir-431</th>\n",
       "      <th>brain-mir-23:brain-mir-23</th>\n",
       "      <th>brain-mir-427:brain-mir-427</th>\n",
       "      <th>brain-mir-392:brain-mir-392</th>\n",
       "      <th>brain-mir-192:brain-mir-192</th>\n",
       "      <th>brain-mir-53:brain-mir-53</th>\n",
       "      <th>brain-mir-112:brain-mir-112</th>\n",
       "      <th>brain-mir-159:brain-mir-159</th>\n",
       "      <th>brain-mir-328:brain-mir-328</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AD.1</th>\n",
       "      <td>132.885714</td>\n",
       "      <td>958.457143</td>\n",
       "      <td>78.957143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3546.471429</td>\n",
       "      <td>117.857143</td>\n",
       "      <td>21.828571</td>\n",
       "      <td>902.114286</td>\n",
       "      <td>6335.742857</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>21.828571</td>\n",
       "      <td>12.471429</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>6.385714</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>13.571429</td>\n",
       "      <td>310.414286</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.2</th>\n",
       "      <td>282.371429</td>\n",
       "      <td>794.542857</td>\n",
       "      <td>64.457143</td>\n",
       "      <td>1.542857</td>\n",
       "      <td>14464.157143</td>\n",
       "      <td>40.428571</td>\n",
       "      <td>35.728571</td>\n",
       "      <td>1840.628571</td>\n",
       "      <td>3969.000000</td>\n",
       "      <td>5.157143</td>\n",
       "      <td>...</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>23.942857</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>16.985714</td>\n",
       "      <td>10.485714</td>\n",
       "      <td>7.414286</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>297.985714</td>\n",
       "      <td>16.371429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.3</th>\n",
       "      <td>179.371429</td>\n",
       "      <td>541.785714</td>\n",
       "      <td>69.814286</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>8648.271429</td>\n",
       "      <td>18.542857</td>\n",
       "      <td>23.057143</td>\n",
       "      <td>1459.242857</td>\n",
       "      <td>2045.757143</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>19.085714</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>14.871429</td>\n",
       "      <td>275.814286</td>\n",
       "      <td>16.185714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.4</th>\n",
       "      <td>115.700000</td>\n",
       "      <td>1011.342857</td>\n",
       "      <td>65.542857</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>7038.985714</td>\n",
       "      <td>72.342857</td>\n",
       "      <td>31.471429</td>\n",
       "      <td>289.042857</td>\n",
       "      <td>2860.557143</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>9.514286</td>\n",
       "      <td>28.257143</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>9.514286</td>\n",
       "      <td>7.185714</td>\n",
       "      <td>13.442857</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>275.814286</td>\n",
       "      <td>14.757143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.5</th>\n",
       "      <td>89.857143</td>\n",
       "      <td>429.757143</td>\n",
       "      <td>32.228571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4315.285714</td>\n",
       "      <td>84.800000</td>\n",
       "      <td>27.728571</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>1621.442857</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>...</td>\n",
       "      <td>15.428571</td>\n",
       "      <td>9.514286</td>\n",
       "      <td>37.728571</td>\n",
       "      <td>27.728571</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>15.428571</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>187.242857</td>\n",
       "      <td>6.457143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 220 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('E:\\FYP\\datasets\\Special\\GSE46579_AD_ngs_data_summarized_new.xls',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"class\",1)\n",
    "y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = ['hsa-mir-30d:hsa-miR-30d-5p',\n",
    " 'hsa-let-7f-1:hsa-let-7f-5p',\n",
    " 'hsa-mir-144:hsa-miR-144-5p',\n",
    " 'hsa-mir-98:hsa-miR-98',\n",
    " 'hsa-mir-148a:hsa-miR-148a-3p',\n",
    " 'hsa-mir-589:hsa-miR-589-5p',\n",
    " 'hsa-mir-186:hsa-miR-186-5p',\n",
    " 'hsa-mir-99b:hsa-miR-99b-5p',\n",
    " 'hsa-mir-144:hsa-miR-144-3p',\n",
    " 'hsa-mir-151a:hsa-miR-151a-3p',\n",
    " 'hsa-let-7a-1:hsa-let-7a-5p',\n",
    " 'hsa-let-7g:hsa-let-7g-5p',\n",
    " 'hsa-mir-15a:hsa-miR-15a-5p',\n",
    " 'hsa-let-7f-2:hsa-let-7f-5p']\n",
    "\n",
    "correlations_selected = ['hsa-mir-4781:hsa-miR-4781-3p',\n",
    "'brain-mir-112:brain-mir-112',\n",
    "'hsa-let-7a-3:hsa-let-7a-5p',\n",
    "'hsa-mir-148b:hsa-miR-148b-5p',\n",
    "'hsa-mir-29b-2:hsa-miR-29b-3p',\n",
    "'brain-mir-431:brain-mir-431',\n",
    "'hsa-mir-378a:hsa-miR-378a-5p',\n",
    "'hsa-mir-548h-5:hsa-miR-548h-5p',\n",
    "'hsa-mir-3909:hsa-miR-3909',\n",
    "'hsa-mir-625:hsa-miR-625-5p',\n",
    "'hsa-mir-24-1:hsa-miR-24-3p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find TP - True Possitive rate, FP - False Positive rate, TN - True Negative rate and FN - False Negative rate\n",
    "# To find Sensitivity and Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y actual\nAD.23         1\nAD.1          1\ncontrol.14    0\nAD.5          1\ncontrol.20    0\nAD.19         1\nAD.11         1\ncontrol       0\ncontrol.11    0\nAD.13         1\nAD.32         1\nAD.10         1\nAD.38         1\nAD.6          1\nAD.47         1\nAD.31         1\nAD.36         1\ncontrol.2     0\nAD.35         1\ncontrol.13    0\nAD.17         1\nName: class, dtype: int64\nY predict\n[1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "tmp_DF = X[overlap]\n",
    "X_train, X_test, y_train, y_test = train_test_split(tmp_DF, y, test_size=0.3, random_state=42)\n",
    "\n",
    "svm_classifierf = svm.SVC(kernel='linear') \n",
    "score_svm_li = cross_val_score(svm_classifierf, X_train, y_train, cv=3)\n",
    "svm_classifierf.fit(X_train, y_train)\n",
    "predicted_SVM = svm_classifierf.predict(X_test)\n",
    "\n",
    "print(\"Y actual\")\n",
    "print(y_test)\n",
    "print(\"Y predict\")\n",
    "print(predicted_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  3],\n       [ 1, 14]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, predicted_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.75      0.50      0.60         6\\n           1       0.82      0.93      0.87        15\\n\\n    accuracy                           0.81        21\\n   macro avg       0.79      0.72      0.74        21\\nweighted avg       0.80      0.81      0.80        21\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.classification_report(y_test, predicted_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, TN, FN = perf_measure(y_test, predicted_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 3, 3, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity =  0.9333333333333333\nSpecificity =  0.5\n"
     ]
    }
   ],
   "source": [
    "Sensitivity = TP/(TP+FN)\n",
    "Specificity = TN/(TN+FP)\n",
    "\n",
    "print(\"Sensitivity = \", Sensitivity)\n",
    "print(\"Specificity = \", Specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(tmp_DF, y): \n",
    "    X_train, X_test, y_train, y_test = train_test_split(tmp_DF, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    svm_classifier = svm.SVC(kernel='linear') \n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    predicted_SVM = svm_classifier.predict(X_test)\n",
    "\n",
    "    LR_classifier = LogisticRegression(random_state=42)\n",
    "    LR_classifier.fit(X_train, y_train)\n",
    "    predected_LR = LR_classifier.predict(X_test)\n",
    "  \n",
    "    RF_classifier = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=42)\n",
    "    RF_classifier.fit(X_train, y_train)\n",
    "    predicted_RF = RF_classifier.predict(X_test)\n",
    "  \n",
    "    TP1, FP1, TN1, FN1 = perf_measure(y_test, predicted_SVM)\n",
    "    TP2, FP2, TN2, FN2 = perf_measure(y_test, predected_LR)\n",
    "    TP3, FP3, TN3, FN3 = perf_measure(y_test, predicted_RF)\n",
    "  \n",
    "    print(\"LinearSVM \\t\\t\\t Sensitivity = \", TP1/(TP1+FN1), \"\\t\\tSpecificity = \", TN1/(TN1+FP1))\n",
    "    print(\"Logistic Regression \\t\\t Sensitivity = \", TP2/(TP2+FN2), \"\\t\\tSpecificity = \", TN2/(TN2+FP2))\n",
    "    print(\"Random Forests \\t\\t Sensitivity = \", TP3/(TP3+FN3), \"\\t\\tSpecificity = \", TN3/(TN3+FP3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVM \t\t\t Sensitivity =  0.9333333333333333 \t\tSpecificity =  0.5\nLogistic Regression \t\t Sensitivity =  0.9333333333333333 \t\tSpecificity =  1.0\nRandom Forests \t\t Sensitivity =  0.8666666666666667 \t\tSpecificity =  1.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Overlap set\")\n",
    "\n",
    "tmp_DF = X[overlap]\n",
    "results(tmp_DF, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlations_selected set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVM \t\t\t Sensitivity =  0.9333333333333333 \t\tSpecificity =  1.0\nLogistic Regression \t\t Sensitivity =  0.9333333333333333 \t\tSpecificity =  1.0\nRandom Forests \t\t Sensitivity =  0.9333333333333333 \t\tSpecificity =  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"correlations_selected set\")\n",
    "\n",
    "tmp_DF = X[correlations_selected]\n",
    "results(tmp_DF, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVM \t\t\t Sensitivity =  0.8666666666666667 \t\tSpecificity =  0.8333333333333334\nLogistic Regression \t\t Sensitivity =  1.0 \t\tSpecificity =  1.0\nRandom Forests \t\t Sensitivity =  0.9333333333333333 \t\tSpecificity =  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"final set\")\n",
    "\n",
    "tmp_DF = X[overlap + correlations_selected]\n",
    "results(tmp_DF, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
