{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsa-mir-30a:hsa-miR-30a-3p</th>\n",
       "      <th>hsa-mir-550a-1:hsa-miR-550a-3p</th>\n",
       "      <th>hsa-mir-29a:hsa-miR-29a-3p</th>\n",
       "      <th>hsa-mir-628:hsa-miR-628-3p</th>\n",
       "      <th>hsa-mir-26a-2:hsa-miR-26a-5p</th>\n",
       "      <th>hsa-mir-106b:hsa-miR-106b-5p</th>\n",
       "      <th>hsa-mir-4781:hsa-miR-4781-3p</th>\n",
       "      <th>hsa-mir-10b:hsa-miR-10b-5p</th>\n",
       "      <th>hsa-mir-215:hsa-miR-215</th>\n",
       "      <th>hsa-mir-548aj-2:hsa-miR-548g-5p</th>\n",
       "      <th>...</th>\n",
       "      <th>brain-mir-431:brain-mir-431</th>\n",
       "      <th>brain-mir-23:brain-mir-23</th>\n",
       "      <th>brain-mir-427:brain-mir-427</th>\n",
       "      <th>brain-mir-392:brain-mir-392</th>\n",
       "      <th>brain-mir-192:brain-mir-192</th>\n",
       "      <th>brain-mir-53:brain-mir-53</th>\n",
       "      <th>brain-mir-112:brain-mir-112</th>\n",
       "      <th>brain-mir-159:brain-mir-159</th>\n",
       "      <th>brain-mir-328:brain-mir-328</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AD.1</th>\n",
       "      <td>132.885714</td>\n",
       "      <td>958.457143</td>\n",
       "      <td>78.957143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3546.471429</td>\n",
       "      <td>117.857143</td>\n",
       "      <td>21.828571</td>\n",
       "      <td>902.114286</td>\n",
       "      <td>6335.742857</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>21.828571</td>\n",
       "      <td>12.471429</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>6.385714</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>13.571429</td>\n",
       "      <td>310.414286</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.2</th>\n",
       "      <td>282.371429</td>\n",
       "      <td>794.542857</td>\n",
       "      <td>64.457143</td>\n",
       "      <td>1.542857</td>\n",
       "      <td>14464.157143</td>\n",
       "      <td>40.428571</td>\n",
       "      <td>35.728571</td>\n",
       "      <td>1840.628571</td>\n",
       "      <td>3969.000000</td>\n",
       "      <td>5.157143</td>\n",
       "      <td>...</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>23.942857</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>16.985714</td>\n",
       "      <td>10.485714</td>\n",
       "      <td>7.414286</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>297.985714</td>\n",
       "      <td>16.371429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.3</th>\n",
       "      <td>179.371429</td>\n",
       "      <td>541.785714</td>\n",
       "      <td>69.814286</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>8648.271429</td>\n",
       "      <td>18.542857</td>\n",
       "      <td>23.057143</td>\n",
       "      <td>1459.242857</td>\n",
       "      <td>2045.757143</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>19.085714</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>14.871429</td>\n",
       "      <td>275.814286</td>\n",
       "      <td>16.185714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.4</th>\n",
       "      <td>115.700000</td>\n",
       "      <td>1011.342857</td>\n",
       "      <td>65.542857</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>7038.985714</td>\n",
       "      <td>72.342857</td>\n",
       "      <td>31.471429</td>\n",
       "      <td>289.042857</td>\n",
       "      <td>2860.557143</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>9.514286</td>\n",
       "      <td>28.257143</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>9.514286</td>\n",
       "      <td>7.185714</td>\n",
       "      <td>13.442857</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>275.814286</td>\n",
       "      <td>14.757143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.5</th>\n",
       "      <td>89.857143</td>\n",
       "      <td>429.757143</td>\n",
       "      <td>32.228571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4315.285714</td>\n",
       "      <td>84.800000</td>\n",
       "      <td>27.728571</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>1621.442857</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>...</td>\n",
       "      <td>15.428571</td>\n",
       "      <td>9.514286</td>\n",
       "      <td>37.728571</td>\n",
       "      <td>27.728571</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>15.428571</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>187.242857</td>\n",
       "      <td>6.457143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsa-mir-30a:hsa-miR-30a-3p</th>\n",
       "      <th>hsa-mir-550a-1:hsa-miR-550a-3p</th>\n",
       "      <th>hsa-mir-29a:hsa-miR-29a-3p</th>\n",
       "      <th>hsa-mir-628:hsa-miR-628-3p</th>\n",
       "      <th>hsa-mir-26a-2:hsa-miR-26a-5p</th>\n",
       "      <th>hsa-mir-106b:hsa-miR-106b-5p</th>\n",
       "      <th>hsa-mir-4781:hsa-miR-4781-3p</th>\n",
       "      <th>hsa-mir-10b:hsa-miR-10b-5p</th>\n",
       "      <th>hsa-mir-215:hsa-miR-215</th>\n",
       "      <th>hsa-mir-548aj-2:hsa-miR-548g-5p</th>\n",
       "      <th>...</th>\n",
       "      <th>brain-mir-431:brain-mir-431</th>\n",
       "      <th>brain-mir-23:brain-mir-23</th>\n",
       "      <th>brain-mir-427:brain-mir-427</th>\n",
       "      <th>brain-mir-392:brain-mir-392</th>\n",
       "      <th>brain-mir-192:brain-mir-192</th>\n",
       "      <th>brain-mir-53:brain-mir-53</th>\n",
       "      <th>brain-mir-112:brain-mir-112</th>\n",
       "      <th>brain-mir-159:brain-mir-159</th>\n",
       "      <th>brain-mir-328:brain-mir-328</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AD.1</th>\n",
       "      <td>132.885714</td>\n",
       "      <td>958.457143</td>\n",
       "      <td>78.957143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3546.471429</td>\n",
       "      <td>117.857143</td>\n",
       "      <td>21.828571</td>\n",
       "      <td>902.114286</td>\n",
       "      <td>6335.742857</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>21.828571</td>\n",
       "      <td>12.471429</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>6.385714</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>13.571429</td>\n",
       "      <td>310.414286</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.2</th>\n",
       "      <td>282.371429</td>\n",
       "      <td>794.542857</td>\n",
       "      <td>64.457143</td>\n",
       "      <td>1.542857</td>\n",
       "      <td>14464.157143</td>\n",
       "      <td>40.428571</td>\n",
       "      <td>35.728571</td>\n",
       "      <td>1840.628571</td>\n",
       "      <td>3969.000000</td>\n",
       "      <td>5.157143</td>\n",
       "      <td>...</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>23.942857</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>16.985714</td>\n",
       "      <td>10.485714</td>\n",
       "      <td>7.414286</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>297.985714</td>\n",
       "      <td>16.371429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.3</th>\n",
       "      <td>179.371429</td>\n",
       "      <td>541.785714</td>\n",
       "      <td>69.814286</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>8648.271429</td>\n",
       "      <td>18.542857</td>\n",
       "      <td>23.057143</td>\n",
       "      <td>1459.242857</td>\n",
       "      <td>2045.757143</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>19.085714</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>14.871429</td>\n",
       "      <td>275.814286</td>\n",
       "      <td>16.185714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.4</th>\n",
       "      <td>115.700000</td>\n",
       "      <td>1011.342857</td>\n",
       "      <td>65.542857</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>7038.985714</td>\n",
       "      <td>72.342857</td>\n",
       "      <td>31.471429</td>\n",
       "      <td>289.042857</td>\n",
       "      <td>2860.557143</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>9.514286</td>\n",
       "      <td>28.257143</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>9.514286</td>\n",
       "      <td>7.185714</td>\n",
       "      <td>13.442857</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>275.814286</td>\n",
       "      <td>14.757143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD.5</th>\n",
       "      <td>89.857143</td>\n",
       "      <td>429.757143</td>\n",
       "      <td>32.228571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4315.285714</td>\n",
       "      <td>84.800000</td>\n",
       "      <td>27.728571</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>1621.442857</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>...</td>\n",
       "      <td>15.428571</td>\n",
       "      <td>9.514286</td>\n",
       "      <td>37.728571</td>\n",
       "      <td>27.728571</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>15.428571</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>187.242857</td>\n",
       "      <td>6.457143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 220 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('E:\\FYP\\datasets\\Special\\GSE46579_AD_ngs_data_summarized_new.xls',index_col=0)\n",
    "df.head()\n",
    "#df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"class\",1)\n",
    "y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_50 = ['hsa-mir-92b:hsa-miR-92b-3p', \n",
    "'hsa-mir-484:hsa-miR-484', \n",
    "'hsa-mir-30d:hsa-miR-30d-5p', \n",
    "'hsa-let-7a-1:hsa-let-7a-5p',\n",
    "'hsa-let-7f-2:hsa-let-7f-5p',\n",
    "'hsa-mir-148a:hsa-miR-148a-3p',\n",
    "'hsa-let-7f-1:hsa-let-7f-5p',\n",
    "'hsa-mir-363:hsa-miR-363-3p',\n",
    "'hsa-let-7g:hsa-let-7g-5p',\n",
    "'hsa-mir-151a:hsa-miR-151a-3p',\n",
    "'hsa-let-7e:hsa-let-7e-5p',\n",
    "'hsa-mir-186:hsa-miR-186-5p',\n",
    "'hsa-let-7c:hsa-let-7c',\n",
    "'hsa-mir-15a:hsa-miR-15a-5p',\n",
    "'hsa-mir-423:hsa-miR-423-3p',\n",
    "'hsa-mir-144:hsa-miR-144-5p',\n",
    "'hsa-mir-215:hsa-miR-215',\n",
    "'hsa-mir-103a-1:hsa-miR-103a-3p',\n",
    "'hsa-mir-3615:hsa-miR-3615',\n",
    "'hsa-let-7b:hsa-let-7b-5p',\n",
    "'hsa-mir-106b:hsa-miR-106b-3p',\n",
    "'hsa-mir-128-1:hsa-miR-128',\n",
    "'hsa-mir-28:hsa-miR-28-3p',\n",
    "'hsa-mir-1260b:hsa-miR-1260b',\n",
    "'hsa-let-7d:hsa-let-7d-3p',\n",
    "'hsa-mir-25:hsa-miR-25-3p',\n",
    "'hsa-mir-942:hsa-miR-942',\n",
    "'hsa-mir-3605:hsa-miR-3605-3p',\n",
    "'hsa-mir-151b:hsa-miR-151b',\n",
    "'hsa-mir-223:hsa-miR-223-3p',\n",
    "'hsa-mir-98:hsa-miR-98',\n",
    "'hsa-mir-125a:hsa-miR-125a-5p',\n",
    "'hsa-mir-126:hsa-miR-126-3p',\n",
    "'hsa-mir-148b:hsa-miR-148b-3p',\n",
    "'hsa-mir-144:hsa-miR-144-3p',\n",
    "'hsa-mir-143:hsa-miR-143-3p',\n",
    "'hsa-mir-345:hsa-miR-345-5p',\n",
    "'hsa-mir-5010:hsa-miR-5010-3p',\n",
    "'hsa-mir-99b:hsa-miR-99b-5p',\n",
    "'hsa-mir-589:hsa-miR-589-5p',\n",
    "'hsa-mir-3158-2:hsa-miR-3158-3p',\n",
    "'hsa-mir-550a-1:hsa-miR-550a-3p',\n",
    "'hsa-mir-30a:hsa-miR-30a-3p',\n",
    "'hsa-mir-576:hsa-miR-576-5p',\n",
    "'hsa-mir-339:hsa-miR-339-3p',\n",
    "'hsa-let-7d:hsa-let-7d-5p',\n",
    "'brain-mir-159:brain-mir-159',\n",
    "'hsa-mir-185:hsa-miR-185-5p',\n",
    "'hsa-mir-1307:hsa-miR-1307-3p',\n",
    "'hsa-mir-93:hsa-miR-93-3p']\n",
    "\n",
    "rf_50 = ['hsa-mir-30d:hsa-miR-30d-5p',\n",
    "'hsa-mir-144:hsa-miR-144-5p',\n",
    "'hsa-mir-4781:hsa-miR-4781-3p',\n",
    "'hsa-let-7a-1:hsa-let-7a-5p',\n",
    "'brain-mir-112:brain-mir-112',\n",
    "'hsa-let-7f-1:hsa-let-7f-5p',\n",
    "'hsa-mir-3157:hsa-miR-3157-3p',\n",
    "'hsa-let-7f-2:hsa-let-7f-5p',\n",
    "'hsa-mir-151a:hsa-miR-151a-3p',\n",
    "'hsa-let-7g:hsa-let-7g-5p',\n",
    "'hsa-let-7a-3:hsa-let-7a-5p',\n",
    "'hsa-mir-425:hsa-miR-425-5p',\n",
    "'hsa-mir-17:hsa-miR-17-3p',\n",
    "'hsa-mir-148b:hsa-miR-148b-5p',\n",
    "'hsa-mir-98:hsa-miR-98',\n",
    "'hsa-mir-5001:hsa-miR-5001-3p',\n",
    "'hsa-mir-15a:hsa-miR-15a-5p',\n",
    "'hsa-mir-1285-1:hsa-miR-1285-5p',\n",
    "'hsa-mir-148a:hsa-miR-148a-3p',\n",
    "'hsa-mir-186:hsa-miR-186-5p',\n",
    "'hsa-mir-29b-2:hsa-miR-29b-3p',\n",
    "'hsa-mir-29b-1:hsa-miR-29b-3p',\n",
    "'hsa-mir-1294:hsa-miR-1294',\n",
    "'brain-mir-431:brain-mir-431',\n",
    "'hsa-mir-550a-3:hsa-miR-550a-3-5p',\n",
    "'hsa-mir-199b:hsa-miR-199a-3p',\n",
    "'hsa-mir-199a-1:hsa-miR-199b-3p',\n",
    "'hsa-mir-199a-2:hsa-miR-199a-3p',\n",
    "'hsa-mir-29c:hsa-miR-29c-3p',\n",
    "'hsa-mir-550a-1:hsa-miR-550a-5p',\n",
    "'hsa-mir-550a-2:hsa-miR-550a-5p',\n",
    "'hsa-mir-199a-2:hsa-miR-199b-3p',\n",
    "'hsa-mir-199b:hsa-miR-199b-3p',\n",
    "'hsa-mir-550a-1:hsa-miR-550a-3-5p',\n",
    "'hsa-let-7a-2:hsa-let-7a-5p',\n",
    "'hsa-mir-29a:hsa-miR-29a-3p',\n",
    "'hsa-mir-199a-1:hsa-miR-199a-3p',\n",
    "'brain-mir-219:brain-mir-219',\n",
    "'hsa-mir-550a-2:hsa-miR-550a-3-5p',\n",
    "'hsa-mir-99b:hsa-miR-99b-5p',\n",
    "'hsa-mir-144:hsa-miR-144-3p',\n",
    "'hsa-mir-30a:hsa-miR-30a-5p',\n",
    "'hsa-mir-378a:hsa-miR-378a-5p',\n",
    "'hsa-mir-128-2:hsa-miR-128',\n",
    "'hsa-mir-2110:hsa-miR-2110',\n",
    "'hsa-mir-589:hsa-miR-589-5p',\n",
    "'hsa-mir-548h-5:hsa-miR-548h-5p',\n",
    "'hsa-mir-3909:hsa-miR-3909',\n",
    "'hsa-mir-625:hsa-miR-625-5p',\n",
    "'hsa-mir-24-1:hsa-miR-24-3p']\n",
    "\n",
    "overlap = ['hsa-mir-30d:hsa-miR-30d-5p',\n",
    " 'hsa-let-7f-1:hsa-let-7f-5p',\n",
    " 'hsa-mir-144:hsa-miR-144-5p',\n",
    " 'hsa-mir-98:hsa-miR-98',\n",
    " 'hsa-mir-148a:hsa-miR-148a-3p',\n",
    " 'hsa-mir-589:hsa-miR-589-5p',\n",
    " 'hsa-mir-186:hsa-miR-186-5p',\n",
    " 'hsa-mir-99b:hsa-miR-99b-5p',\n",
    " 'hsa-mir-144:hsa-miR-144-3p',\n",
    " 'hsa-mir-151a:hsa-miR-151a-3p',\n",
    " 'hsa-let-7a-1:hsa-let-7a-5p',\n",
    " 'hsa-let-7g:hsa-let-7g-5p',\n",
    " 'hsa-mir-15a:hsa-miR-15a-5p',\n",
    " 'hsa-let-7f-2:hsa-let-7f-5p']\n",
    "\n",
    "correlations_selected = ['hsa-mir-4781:hsa-miR-4781-3p',\n",
    "'brain-mir-112:brain-mir-112',\n",
    "'hsa-let-7a-3:hsa-let-7a-5p',\n",
    "'hsa-mir-148b:hsa-miR-148b-5p',\n",
    "'hsa-mir-29b-2:hsa-miR-29b-3p',\n",
    "'brain-mir-431:brain-mir-431',\n",
    "'hsa-mir-378a:hsa-miR-378a-5p',\n",
    "'hsa-mir-548h-5:hsa-miR-548h-5p',\n",
    "'hsa-mir-3909:hsa-miR-3909',\n",
    "'hsa-mir-625:hsa-miR-625-5p',\n",
    "'hsa-mir-24-1:hsa-miR-24-3p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificationResults(dataFrame, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataFrame, y, test_size=0.35, random_state=1)\n",
    "    \n",
    "    svm_classifier = svm.SVC(kernel='linear') \n",
    "    crossScore_svm = cross_val_score(svm_classifier, X_train, y_train, cv=5)\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    svm_predicted = svm_classifier.predict(X_test)\n",
    "\n",
    "    LR_classifier = LogisticRegression(random_state=42)\n",
    "    crossScore_LR = cross_val_score(LR_classifier, X_train, y_train, cv=5)\n",
    "    LR_classifier.fit(X_train, y_train)\n",
    "    LR_predicted = LR_classifier.predict(X_test)\n",
    "  \n",
    "    RF_classifier = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=1)\n",
    "    crossScore_RF = cross_val_score(RF_classifier, X_train, y_train, cv=5)\n",
    "    RF_classifier.fit(X_train, y_train)\n",
    "    RF_predicted = RF_classifier.predict(X_test)\n",
    "\n",
    "    print(\"Training and Testing accuracies of linear SVM model\")\n",
    "    print(\"Testing: \" , round(metrics.accuracy_score(np.int64(y_test.values), svm_predicted)*100,2) ,\"Training: \", round(crossScore_svm.mean()*100,2))\n",
    "  \n",
    "    print(\"Training and Testing accuracies of Logistic Regression model\")\n",
    "    print(\"Testing: \" , round(metrics.accuracy_score(np.int64(y_test.values), LR_predicted)*100,2) ,\"Training: \", round(crossScore_LR.mean()*100,2))\n",
    "\n",
    "    print(\"Training and Testing accuracies of Random Forest model\")\n",
    "    print(\"Testing: \" , round(metrics.accuracy_score(np.int64(y_test.values), RF_predicted)*100,2) ,\"Training: \", round(crossScore_RF.mean()*100,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 miRNA from PCA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing accuracies of linear SVM model\nTesting:  68.0 Training:  88.89\nTraining and Testing accuracies of Logistic Regression model\nTesting:  64.0 Training:  88.61\nTraining and Testing accuracies of Random Forest model\nTesting:  68.0 Training:  86.39\n\n\n50 miRNA from Random Forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing accuracies of linear SVM model\nTesting:  76.0 Training:  88.61\nTraining and Testing accuracies of Logistic Regression model\nTesting:  72.0 Training:  90.83\nTraining and Testing accuracies of Random Forest model\nTesting:  72.0 Training:  88.61\n\n\nmiRNA from both PCA & RF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing accuracies of linear SVM model\nTesting:  80.0 Training:  90.56\nTraining and Testing accuracies of Logistic Regression model\nTesting:  76.0 Training:  88.33\nTraining and Testing accuracies of Random Forest model\nTesting:  72.0 Training:  88.61\n\n\nmiRNA from correlation matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing accuracies of linear SVM model\nTesting:  96.0 Training:  86.39\nTraining and Testing accuracies of Logistic Regression model\nTesting:  100.0 Training:  93.06\nTraining and Testing accuracies of Random Forest model\nTesting:  72.0 Training:  90.83\n\n\nmiRNA from both PCA & RF and Correlation matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing accuracies of linear SVM model\nTesting:  80.0 Training:  90.56\nTraining and Testing accuracies of Logistic Regression model\nTesting:  76.0 Training:  86.11\nTraining and Testing accuracies of Random Forest model\nTesting:  76.0 Training:  86.39\n\n\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tmp_DF = X[pca_50]\n",
    "print(\"50 miRNA from PCA\") \n",
    "classificationResults(tmp_DF, y) \n",
    "print('\\n')\n",
    "\n",
    "tmp_DF = X[rf_50]\n",
    "print(\"50 miRNA from Random Forest\")\n",
    "classificationResults(tmp_DF, y)\n",
    "print('\\n')\n",
    "\n",
    "tmp_DF = X[overlap]\n",
    "print(\"miRNA from both PCA & RF\")\n",
    "classificationResults(tmp_DF, y)\n",
    "print('\\n')\n",
    "\n",
    "tmp_DF = X[correlations_selected]\n",
    "print(\"miRNA from correlation matrix\")\n",
    "classificationResults(tmp_DF, y) \n",
    "print('\\n')\n",
    "\n",
    "tmp_DF = X[correlations_selected + overlap]\n",
    "print(\"miRNA from both PCA & RF and Correlation matrix\") \n",
    "classificationResults(tmp_DF, y) \n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "   \n",
    "# set width of bar \n",
    "barWidth = 0.25\n",
    "fig = plt.figure(figsize =(8, 6)) \n",
    "   \n",
    "# set height of bar \n",
    "Test = [85.71, 95.24, 95.24] \n",
    "Train = [81.25, 75.0, 89.58] \n",
    "   \n",
    "# Set position of bar on X axis \n",
    "br1 = np.arange(len(Test)) \n",
    "br2 = [x + barWidth for x in br1]  \n",
    "   \n",
    "# Make the plot \n",
    "plt.bar(br1, Test, color ='r', width = barWidth, \n",
    "        edgecolor ='grey', label ='Test') \n",
    "plt.bar(br2, Train, color ='g', width = barWidth, \n",
    "        edgecolor ='grey', label ='Train')  \n",
    "   \n",
    "# Adding Xticks  \n",
    "plt.xlabel('Machine Learning Algorithm', fontweight ='bold') \n",
    "plt.ylabel('Accuracy', fontweight ='bold') \n",
    "plt.xticks([r + 0.125 for r in range(len(Test))], \n",
    "           ['Linear SVM', 'Logistic Regression', 'Random Forests']) \n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('E:\\FYP\\Figures_1stDataset\\Train_Test_accuracy(final_set).png')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracies of final selected feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing accuracies of linear SVM model\n",
    "# Testing:  80.95 Training:  81.25\n",
    "\n",
    "# Training and Testing accuracies of Random forest model\n",
    "# Testing:  95.24 Training:  77.08\n",
    "\n",
    "# Training and Testing accuracies of Logistic Regression model\n",
    "# Testing:  90.48 Training:  85.42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_excel('E:\\FYP\\datasets\\Special\\Book1.xlsx',index_col=0)\n",
    "#original_df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = original_df.drop(\"class\",1)\n",
    "y_new = original_df[\"class\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 miRNA from PCA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing accuracies of linear SVM model\nTesting:  100.0 Training:  100.0\nTraining and Testing accuracies of Logistic Regression model\nTesting:  100.0 Training:  100.0\nTraining and Testing accuracies of Random Forest model\nTesting:  98.57 Training:  90.95\n\n\n50 miRNA from Random Forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing accuracies of linear SVM model\nTesting:  100.0 Training:  99.52\nTraining and Testing accuracies of Logistic Regression model\nTesting:  100.0 Training:  99.52\nTraining and Testing accuracies of Random Forest model\nTesting:  100.0 Training:  96.19\n\n\nmiRNA from both PCA & RF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing accuracies of linear SVM model\nTesting:  100.0 Training:  100.0\nTraining and Testing accuracies of Logistic Regression model\nTesting:  98.57 Training:  96.67\nTraining and Testing accuracies of Random Forest model\nTesting:  98.57 Training:  93.81\n\n\nmiRNA from correlation matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing accuracies of linear SVM model\nTesting:  94.29 Training:  90.95\nTraining and Testing accuracies of Logistic Regression model\nTesting:  94.29 Training:  94.76\nTraining and Testing accuracies of Random Forest model\nTesting:  91.43 Training:  93.33\n\n\nmiRNA from both PCA & RF and Correlation matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing accuracies of linear SVM model\nTesting:  100.0 Training:  100.0\nTraining and Testing accuracies of Logistic Regression model\nTesting:  98.57 Training:  96.67\nTraining and Testing accuracies of Random Forest model\nTesting:  92.86 Training:  95.71\n\n\n"
     ]
    }
   ],
   "source": [
    "tmp_DF = X_new[pca_50]\n",
    "print(\"50 miRNA from PCA\") \n",
    "classificationResults(tmp_DF, y_new) \n",
    "print('\\n')\n",
    "\n",
    "tmp_DF = X_new[rf_50]\n",
    "print(\"50 miRNA from Random Forest\")\n",
    "classificationResults(tmp_DF, y_new)\n",
    "print('\\n')\n",
    "\n",
    "tmp_DF = X_new[overlap]\n",
    "print(\"miRNA from both PCA & RF\")\n",
    "classificationResults(tmp_DF, y_new)\n",
    "print('\\n')\n",
    "\n",
    "tmp_DF = X_new[correlations_selected]\n",
    "print(\"miRNA from correlation matrix\")\n",
    "classificationResults(tmp_DF, y_new) \n",
    "print('\\n')\n",
    "\n",
    "tmp_DF = X_new[correlations_selected + overlap]\n",
    "print(\"miRNA from both PCA & RF and Correlation matrix\") \n",
    "classificationResults(tmp_DF, y_new) \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
